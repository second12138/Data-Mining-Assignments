---
title: "STAT 2450 Assignment 6, Winter 2019 - due Wednesday, March 20, at beginning of class"
author: "Yansong Li"
date: 'Banner:  B00755354'
output:
  html_document: default
  word_document: default
  pdf_document: default
---
1.  Plot a histogram of the bootstrap distribution of the estimated slope
parameter for the hardwood data.

   + a convenient way to incorporate a bootstrap sample from the pairs
   ($x_i,y_i$), is as follows.

     lm(y~x,subset=sample(1:n,n,replace=T)

   + then extract the estimated slope using coef(lm.out)[2]


```{r}
rm(list=ls())
set.seed(999123)
x = c(1,1.5,2,3,4,4.5,5,5.5,6,6.5,7,8,9,10,11,12,13,14,15)
y = c(6.3,11.1,20,24,26.1,30,33.8,34.0,38.1,39.9,42,46.1,53.1,52,52.5,48,42.8,27.8,21.9)
   n=length(y)
   temp=NULL
   for (i in 1:1000){
    lm.out = lm(y~x,subset=sample(1:n,n,replace=T))
    beta1hat = coef(lm.out)[2]
    temp[i] = beta1hat
   }
```

   + (a) make a histogram of the estimated slopes
   
```{r}
hist(temp)
```

   + (b) use the quantile function to calculate a 90% percentile interval
   
```{r}
quantile(temp,probs=c(.05,.95))
```

   + (c) estimate the variance of $\hat \beta_1$.
   
```{r}
var(temp)
```


2.  Explore the sensitivity of the bootstrap estimate of the standard
error of the slope estimate using the "boot" procedure, using the
hardwood data.

   +  Run the boot procedure 10 times with a bootstrap sample size of 10.
   
```{r}
rm(list=ls())
set.seed(999123)
x = c(1,1.5,2,3,4,4.5,5,5.5,6,6.5,7,8,9,10,11,12,13,14,15)
y = c(6.3,11.1,20,24,26.1,30,33.8,34.0,38.1,39.9,42,46.1,53.1,52,52.5,48,42.8,27.8,21.9)
data = data.frame(x=x,y=y)
library(boot)
beta1hat =function(data,i){
  x=x[i]
  y=y[i]
  lmout=lm(y~x)
  beta1hat=coef(lmout)[2]
  return(beta1hat)
}
boot(data,beta1hat,R=10)
boot(data,beta1hat,R=10)
boot(data,beta1hat,R=10)
boot(data,beta1hat,R=10)
boot(data,beta1hat,R=10)
boot(data,beta1hat,R=10)
boot(data,beta1hat,R=10)
boot(data,beta1hat,R=10)
boot(data,beta1hat,R=10)
boot(data,beta1hat,R=10)
```
   
   +  Run the boot procedure 10 times with a bootstrap sample size of 100.
   
```{r}
boot(data,beta1hat,R=100)
boot(data,beta1hat,R=100)
boot(data,beta1hat,R=100)
boot(data,beta1hat,R=100)
boot(data,beta1hat,R=100)
boot(data,beta1hat,R=100)
boot(data,beta1hat,R=100)
boot(data,beta1hat,R=100)
boot(data,beta1hat,R=100)
boot(data,beta1hat,R=100)
```
   
   +  Run the boot procedure 10 times with a bootstrap sample size of 1000.
   
```{r}
boot(data,beta1hat,R=1000)
boot(data,beta1hat,R=1000)
boot(data,beta1hat,R=1000)
boot(data,beta1hat,R=1000)
boot(data,beta1hat,R=1000)
boot(data,beta1hat,R=1000)
boot(data,beta1hat,R=1000)
boot(data,beta1hat,R=1000)
boot(data,beta1hat,R=1000)
boot(data,beta1hat,R=1000)
```
   

    How does the variability of the bootstrap estimate of standard error
    change as the number of bootstrap samples increases?
    
    Answer: The data of standard error is getting more and more stable(changing in a smaller range) along with the increasing number of bootstrap samples
